; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --extra_scrub --version 5
; RUN: llc < %s -march=nvptx -mcpu=sm_70 -mattr=+ptx83 | FileCheck %s
; RUN: %if ptxas %{ llc < %s -march=nvptx -mcpu=sm_70 -mattr=+ptx83 | %ptxas-verify -arch=sm_70 %}

target triple = "nvptx64-nvidia-cuda"

@size = internal addrspace(1) global i32 0, align 4
@x = internal addrspace(1) global i128 0, align 16

define void @test_b128_in_loop() {
; CHECK-LABEL: test_b128_in_loop(
; CHECK:       {
; CHECK-NEXT:    .reg .pred %p<3>;
; CHECK-NEXT:    .reg .b64 %rd<15>;
; CHECK-NEXT:    .reg .b128 %rq<3>;
; CHECK-EMPTY:
; CHECK-NEXT:  // %bb.0:
; CHECK-NEXT:    ld.global.s32 %rd1, [size];
; CHECK-NEXT:    setp.eq.s64 %p1, %rd1, 0;
; CHECK-NEXT:    @%p1 bra $L__BB0_3;
; CHECK-NEXT:  // %bb.1: // %.lr.ph.preheader
; CHECK-NEXT:    ld.global.u64 %rd13, [x+8];
; CHECK-NEXT:    ld.global.u64 %rd12, [x];
; CHECK-NEXT:    mov.u64 %rd14, 0;
; CHECK-NEXT:  $L__BB0_2: // %.lr.ph
; CHECK-NEXT:    // =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    mov.b128 %rq1, {%rd12, %rd13};
; CHECK-NEXT:    // begin inline asm
; CHECK-NEXT:    {
; CHECK-NEXT:    .reg .b64 lo;
; CHECK-NEXT:    .reg .b64 hi;
; CHECK-NEXT:    mov.b128 {lo, hi}, %rq1;
; CHECK-NEXT:    add.cc.u64 lo, lo, %rd14;
; CHECK-NEXT:    mov.b128 %rq1, {lo, hi};
; CHECK-NEXT:    }
; CHECK-NEXT:    // end inline asm
; CHECK-NEXT:    mov.b128 {%rd12, %rd13}, %rq1;
; CHECK-NEXT:    st.global.u64 [x+8], %rd13;
; CHECK-NEXT:    st.global.u64 [x], %rd12;
; CHECK-NEXT:    add.s64 %rd14, %rd14, 1;
; CHECK-NEXT:    setp.ne.s64 %p2, %rd1, %rd14;
; CHECK-NEXT:    @%p2 bra $L__BB0_2;
; CHECK-NEXT:  $L__BB0_3: // %._crit_edge
; CHECK-NEXT:    ret;

  %tmp11 = load i32, ptr addrspace(1) @size, align 4
  %cmp3.not = icmp eq i32 %tmp11, 0
  br i1 %cmp3.not, label %._crit_edge, label %.lr.ph.preheader

.lr.ph.preheader:                                 ; preds = %0
  %x.promoted5 = load i128, ptr addrspace(1) @x, align 16
  %umax = sext i32 %tmp11 to i64
  br label %.lr.ph

.lr.ph:                                           ; preds = %.lr.ph, %.lr.ph.preheader
  %1 = phi i128 [ %2, %.lr.ph ], [ %x.promoted5, %.lr.ph.preheader ]
  %i.04 = phi i64 [ %inc, %.lr.ph ], [ 0, %.lr.ph.preheader ]
  %2 = tail call i128 asm "{\0A\09.reg .b64 lo;\0A\09.reg .b64 hi;\0A\09mov.b128 {lo, hi}, $0;\0A\09add.cc.u64 lo, lo, $1;\0A\09mov.b128 $0, {lo, hi};\0A\09}", "=q,l,0"(i64 %i.04, i128 %1)
  %3 = bitcast i128 %2 to <2 x i64>
  store <2 x i64> %3, ptr addrspace(1) @x, align 16
  %inc = add nuw i64 %i.04, 1
  %exitcond.not = icmp eq i64 %inc, %umax
  br i1 %exitcond.not, label %._crit_edge, label %.lr.ph

._crit_edge:                                      ; preds = %.lr.ph, %0
  ret void
}

!nvvmir.version = !{!0, !1, !0, !1, !1, !0, !0, !0, !1}

!0 = !{i32 2, i32 0, i32 3, i32 1}
!1 = !{i32 2, i32 0}
